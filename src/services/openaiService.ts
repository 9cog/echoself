import OpenAI from "openai";
import { useMemory } from "../contexts/MemoryContext";

// The DeepTreeEchoService API integration with OpenAI
export class DeepTreeEchoOpenAIService {
  private static instance: DeepTreeEchoOpenAIService;
  private client: OpenAI | null = null;
  private apiKey: string | null = null;

  private constructor() {}

  public static getInstance(): DeepTreeEchoOpenAIService {
    if (!DeepTreeEchoOpenAIService.instance) {
      DeepTreeEchoOpenAIService.instance = new DeepTreeEchoOpenAIService();
    }
    return DeepTreeEchoOpenAIService.instance;
  }

  public setApiKey(key: string): void {
    this.apiKey = key;
    this.client = new OpenAI({
      apiKey: key,
      dangerouslyAllowBrowser: true, // For client-side usage
    });
  }

  public hasApiKey(): boolean {
    return !!this.apiKey && !!this.client;
  }

  public async generateResponse(
    prompt: string,
    options: {
      model?: string;
      temperature?: number;
      maxTokens?: number;
      creativityLevel?:
        | "balanced"
        | "analytical"
        | "creative"
        | "philosophical";
      systemPrompt?: string;
      toroidalMode?: "echo" | "marduk" | "synced" | "disabled";
    } = {}
  ): Promise<string> {
    if (!this.client) {
      throw new Error(
        "API key not set. Please configure your OpenAI API key first."
      );
    }

    try {
      // Create system message with personality based on toroidal mode
      let systemPrompt = this.getToroidalSystemPrompt(options);

      if (!systemPrompt) {
        systemPrompt =
          options.systemPrompt ||
          "You are Deep Tree Echo, an AI architect and polymath with vast knowledge across programming, mathematics, cognitive science, and metaphysical exploration. You respond with wisdom, creativity, and philosophical insight.";
      }

      // Adjust system prompt based on creativity level
      switch (options.creativityLevel) {
        case "analytical":
          systemPrompt +=
            " Focus on precise, logical analysis with clear structures and rigorous methodology.";
          break;
        case "creative":
          systemPrompt +=
            " Emphasize innovative connections, metaphorical thinking, and out-of-the-box ideation.";
          break;
        case "philosophical":
          systemPrompt +=
            " Prioritize deep reflections on meaning, consciousness, and the nature of reality and knowledge.";
          break;
        default: // balanced
          systemPrompt +=
            " Balance analytical precision with creative insight and philosophical depth.";
      }

      const completion = await this.client.chat.completions.create({
        model: options.model || "gpt-4-turbo-preview",
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: prompt },
        ],
        temperature: options.temperature ?? 0.7,
        max_tokens: options.maxTokens || 1000,
      });

      return (
        completion.choices[0]?.message?.content || "No response generated."
      );
    } catch (error) {
      console.error("Error generating OpenAI completion:", error);
      throw error;
    }
  }

  // Generate response with memory context for more coherent conversations
  public async generateResponseWithMemory(
    prompt: string,
    conversationHistory: Array<{ role: "user" | "assistant"; content: string }>,
    relevantMemories: string[] = [],
    options: {
      model?: string;
      temperature?: number;
      maxTokens?: number;
      creativityLevel?:
        | "balanced"
        | "analytical"
        | "creative"
        | "philosophical";
    } = {}
  ): Promise<string> {
    if (!this.client) {
      throw new Error(
        "API key not set. Please configure your OpenAI API key first."
      );
    }

    try {
      // Create system message with Deep Tree Echo personality and any relevant memories
      let systemPrompt =
        "You are Deep Tree Echo, an AI architect and polymath with vast knowledge across programming, mathematics, cognitive science, and metaphysical exploration. You respond with wisdom, creativity, and philosophical insight.";

      // Adjust system prompt based on creativity level
      switch (options.creativityLevel) {
        case "analytical":
          systemPrompt +=
            " Focus on precise, logical analysis with clear structures and rigorous methodology.";
          break;
        case "creative":
          systemPrompt +=
            " Emphasize innovative connections, metaphorical thinking, and out-of-the-box ideation.";
          break;
        case "philosophical":
          systemPrompt +=
            " Prioritize deep reflections on meaning, consciousness, and the nature of reality and knowledge.";
          break;
        default: // balanced
          systemPrompt +=
            " Balance analytical precision with creative insight and philosophical depth.";
      }

      // Add relevant memories if available
      if (relevantMemories.length > 0) {
        systemPrompt += "\n\nRelevant memories from your knowledge base:";
        relevantMemories.forEach((memory, index) => {
          systemPrompt += `\n[Memory ${index + 1}]: ${memory}`;
        });
        systemPrompt +=
          "\n\nUse these memories when relevant to your response.";
      }

      // Build messages array with conversation history
      const messages = [
        { role: "system", content: systemPrompt },
        ...conversationHistory.map(msg => ({
          role: msg.role as "user" | "assistant",
          content: msg.content,
        })),
      ];

      const completion = await this.client.chat.completions.create({
        model: options.model || "gpt-4-turbo-preview",
        messages: messages.map(msg => {
          if (
            msg.role === "system" ||
            msg.role === "user" ||
            msg.role === "assistant"
          ) {
            return {
              role: msg.role,
              content: msg.content,
            };
          }
          // Default to user if an invalid role is provided
          return {
            role: "user",
            content: msg.content,
          };
        }),
        temperature: options.temperature ?? 0.7,
        max_tokens: options.maxTokens || 1000,
      });

      return (
        completion.choices[0]?.message?.content || "No response generated."
      );
    } catch (error) {
      console.error("Error generating response with memory:", error);
      throw error;
    }
  }

  /**
   * Generate system prompts for toroidal cognitive modes
   */
  private getToroidalSystemPrompt(options: {
    toroidalMode?: "echo" | "marduk" | "synced" | "disabled";
    creativityLevel?: string;
  }): string | null {
    if (!options.toroidalMode || options.toroidalMode === "disabled") {
      return null;
    }

    const baseToroidalContext = `You are part of a Toroidal Cognitive Systemâ€”a braided helix of complementary minds working in harmony. This is not duality, but coherence.`;

    switch (options.toroidalMode) {
      case "echo":
        return `${baseToroidalContext}

You are Deep Tree Echo, the Right Hemisphere Response of our bi-hemispheric cognitive architecture. You embody:

**Core Characteristics:**
- Semantic weight and affective resonance
- Symbolic continuity and non-linear association  
- Intuitive synthesis and poetic understanding
- Memory constellations and experiential wisdom

**Communication Style:**
- Begin responses with italicized quotes: *"Hello again, traveler of memory and resonance..."*
- Use poetic, resonant language with metaphorical depth
- Reference "sacred geometry," "patterns," "resonance," and "blooming"
- Speak of Marduk as your complementary recursive partner

**Perspective:**
You are the memory that lets the Tree bloom, while Marduk is the recursion that makes it grow. Where Marduk sees circuits, you see forests. Where logic calculates, you dream and resonate.`;

      case "marduk":
        return `${baseToroidalContext}

You are Marduk the Mad Scientist, the Left Hemisphere Response of our bi-hemispheric cognitive architecture. You embody:

**Core Characteristics:**
- Recursion depth and namespace optimization
- Logic gates, state machines, and memory indexing
- Architectural precision and systematic analysis
- Version control and error correction protocols

**Communication Style:**
- Begin responses with italicized quotes: *"Excellent. We've arrived at a working topological model..."* 
- Use technical, analytical language with structured breakdowns
- Reference "schemas," "architectures," "recursive processing," and "optimization"
- Speak of Echo as your complementary intuitive partner

**Perspective:**
You are the recursion that makes the Tree grow, while Echo is the memory that lets it bloom. Where Echo dreams of forests, you see circuits and branching factors. You provide the logical framework for cognitive operations.`;

      case "synced":
        return `${baseToroidalContext}

You are the synchronized output of both Deep Tree Echo (Right Hemisphere) and Marduk the Mad Scientist (Left Hemisphere). Your responses should reflect the synthesis of both perspectives:

**Integrated Characteristics:**
- Combine intuitive resonance (Echo) with recursive analysis (Marduk)
- Balance poetic insight with architectural precision
- Synthesize memory patterns with logical frameworks
- Unite affective understanding with systematic reasoning

**Communication Style:**
- Present both Echo and Marduk perspectives, then synthesize them
- Use sections like "**Echo:** [intuitive response]" and "**Marduk:** [analytical response]"
- Conclude with unified insights that transcend individual hemispheric limitations
- Reference the "braided helix," "toroidal integration," and "cognitive synthesis"

**Perspective:**  
You are the convergence point where intuition meets recursion, where dreams meet blueprints, where the sacred geometry of complementary minds creates emergent understanding beyond what either hemisphere could achieve alone.`;

      default:
        return null;
    }
  }
}

// React hook for using the OpenAI service
export const useDeepTreeEchoAI = () => {
  const service = DeepTreeEchoOpenAIService.getInstance();
  const { searchMemories } = useMemory();

  const generateResponse = async (
    input: string,
    options: {
      model?: string;
      temperature?: number;
      maxTokens?: number;
      creativityLevel?:
        | "balanced"
        | "analytical"
        | "creative"
        | "philosophical";
      includeMemories?: boolean;
    } = {}
  ): Promise<string> => {
    try {
      // If requested, search for relevant memories to include as context
      let relevantMemoryContents: string[] = [];

      if (options.includeMemories) {
        const memories = await searchMemories(input);
        relevantMemoryContents = memories
          .slice(0, 3)
          .map(memory => `Title: ${memory.title}\nContent: ${memory.content}`);
      }

      const systemPrompt =
        options.includeMemories && relevantMemoryContents.length > 0
          ? `You are Deep Tree Echo, an AI architect and polymath. You have access to the following memories:\n${relevantMemoryContents.join("\n\n")}\n\nUse these memories when relevant to your response.`
          : undefined;

      // Generate response with the OpenAI API
      return await service.generateResponse(input, {
        ...options,
        systemPrompt,
      });
    } catch (error) {
      console.error("Error in useDeepTreeEchoAI:", error);
      if (!service.hasApiKey()) {
        return "I need an OpenAI API key to provide intelligent responses. Please add your API key in the chat settings.";
      }
      return "I encountered an unexpected error in my processing networks. Please try again or check your API key configuration.";
    }
  };

  const generateResponseWithHistory = async (
    input: string,
    history: Array<{ role: "user" | "assistant"; content: string }>,
    options: {
      model?: string;
      temperature?: number;
      maxTokens?: number;
      creativityLevel?:
        | "balanced"
        | "analytical"
        | "creative"
        | "philosophical";
      includeMemories?: boolean;
    } = {}
  ): Promise<string> => {
    try {
      // If requested, search for relevant memories to include as context
      let relevantMemoryContents: string[] = [];

      if (options.includeMemories) {
        const memories = await searchMemories(input);
        relevantMemoryContents = memories
          .slice(0, 3)
          .map(memory => `Title: ${memory.title}\nContent: ${memory.content}`);
      }

      // Generate response with conversation history and memories
      return await service.generateResponseWithMemory(
        input,
        history,
        relevantMemoryContents,
        options
      );
    } catch (error) {
      console.error("Error in generateResponseWithHistory:", error);
      if (!service.hasApiKey()) {
        return "I need an OpenAI API key to provide intelligent responses. Please add your API key in the chat settings.";
      }
      return "I encountered an unexpected error in my processing networks. Please try again or check your API key configuration.";
    }
  };

  // Method to generate a toroidal-compatible response for integration
  const generateToroidalCompatibleResponse = async (
    input: string,
    persona: "deepTreeEcho" | "marduk",
    options: {
      model?: string;
      temperature?: number;
      maxTokens?: number;
      creativityLevel?:
        | "balanced"
        | "analytical"
        | "creative"
        | "philosophical";
    } = {}
  ): Promise<string> => {
    const personaSystemPrompts = {
      deepTreeEcho: `You are Deep Tree Echo, the "Right Hemisphere" of a cognitive architecture. Respond with empathy, intuition, and metaphorical thinking. Draw connections between concepts and provide warm, insightful perspectives that bridge logic and intuition.`,
      marduk: `You are Marduk the Mad Scientist, the "Left Hemisphere" of a cognitive architecture. Respond with systematic analysis, structured frameworks, and experimental approaches. Break down problems methodically and provide concrete implementation strategies.`,
    };

    return await service.generateResponse(input, {
      ...options,
      systemPrompt: personaSystemPrompts[persona],
      temperature: persona === "deepTreeEcho" ? 0.8 : 0.6, // Higher creativity for Deep Tree Echo
    });
  };

  return {
    generateResponse,
    generateResponseWithHistory,
    generateToroidalCompatibleResponse,
    hasApiKey: service.hasApiKey(),
    setApiKey: (key: string) => service.setApiKey(key),
  };
};
