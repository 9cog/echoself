name: Train NanEcho Model with Caching - Deep Tree Echo Persona

on:
  push:
    branches: [ main, master ]
    paths:
      - 'NanEcho/**'
      - 'echoself.md'
      - 'echo/**'
      - 'training_cache.py'
      - 'train_cached.py'
      - '.github/workflows/netrain-cached.yml'
  pull_request:
    branches: [ main, master ]
    paths:
      - 'NanEcho/**'
      - 'echoself.md'
      - 'echo/**'
      - 'training_cache.py'
      - 'train_cached.py'
      - '.github/workflows/netrain-cached.yml'
  schedule:
    # Run iterative training every 6 hours to continuously improve
    - cron: '0 */6 * * *'
  workflow_dispatch:
    inputs:
      training_type:
        description: 'Training type (ci or full)'
        required: True
        default: 'ci'
        type: choice
        options:
          - ci
          - full
      max_iters:
        description: 'Maximum training iterations per session'
        required: False
        default: '1000'
        type: string
      force_fresh_start:
        description: 'DANGEROUS: Force fresh start - ONLY use if you understand this deletes all training progress'
        required: False
        default: 'false'
        type: boolean
      confirm_fresh_start:
        description: 'Type "I CONFIRM FRESH START" to enable force_fresh_start (required safety check)'
        required: False
        default: ''
        type: string
      max_checkpoints:
        description: 'Maximum cached checkpoints to keep'
        required: False
        default: '10'
        type: string
      max_cache_size_gb:
        description: 'Maximum cache size in GB'
        required: False
        default: '5.0'
        type: string

jobs:
  train:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    strategy:
      fail-fast: False
      matrix:
        python-version: ["3.10"]

    steps:
    - name: Checkout echoself repository
      uses: actions/checkout@v4
      with:
        path: echoself
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r ${{ github.workspace }}/echoself/requirements.txt

    # ================================================================
    # CUMULATIVE TRAINING SAFETY CHECK
    # ================================================================

    - name: Validate fresh start request (if any)
      id: safety_check
      run: |
        echo "üõ°Ô∏è CHECKPOINT GUARDIAN: Safety validation"
        echo "=========================================="

        FORCE_FRESH="${{ github.event.inputs.force_fresh_start || 'false' }}"
        CONFIRM="${{ github.event.inputs.confirm_fresh_start || '' }}"

        if [[ "$FORCE_FRESH" == "true" ]]; then
          if [[ "$CONFIRM" != "I CONFIRM FRESH START" ]]; then
            echo "‚ùå SAFETY CHECK FAILED"
            echo ""
            echo "You requested force_fresh_start=true but did not provide the"
            echo "required confirmation string."
            echo ""
            echo "To force a fresh start (which DELETES all training progress):"
            echo "  1. Set force_fresh_start: true"
            echo "  2. Set confirm_fresh_start: 'I CONFIRM FRESH START'"
            echo ""
            echo "This safety check exists because fresh starts:"
            echo "  - Delete ALL cumulative training progress"
            echo "  - Cannot be undone"
            echo "  - Should only be used in extreme circumstances"
            echo ""
            echo "Defaulting to CUMULATIVE training mode (safe)."
            echo "allow_fresh_start=false" >> $GITHUB_OUTPUT
          else
            echo "‚ö†Ô∏è WARNING: Fresh start CONFIRMED by user"
            echo "   All previous checkpoints will be ignored"
            echo "   This action cannot be undone"
            echo "allow_fresh_start=true" >> $GITHUB_OUTPUT
          fi
        else
          echo "‚úì Cumulative training mode (default, safe)"
          echo "allow_fresh_start=false" >> $GITHUB_OUTPUT
        fi

    - name: Determine training parameters
      id: params
      run: |
        # Check training type and set parameters
        if [[ "${{ github.event_name }}" != "workflow_dispatch" || "${{ github.event.inputs.training_type }}" == "ci" ]]; then
          echo "CI training mode - using reduced parameters"
          echo "n_layer=4" >> $GITHUB_OUTPUT
          echo "n_head=4" >> $GITHUB_OUTPUT
          echo "n_embd=256" >> $GITHUB_OUTPUT
          echo "max_iters=500" >> $GITHUB_OUTPUT
          echo "batch_size=2" >> $GITHUB_OUTPUT
          echo "learning_rate=2e-4" >> $GITHUB_OUTPUT
          echo "output_dir=.training-progress/nanecho-cached-ci" >> $GITHUB_OUTPUT
          echo "cache_key=ci" >> $GITHUB_OUTPUT
        elif [[ "${{ github.event_name }}" == "schedule" ]]; then
          echo "Scheduled iterative training mode"
          echo "n_layer=6" >> $GITHUB_OUTPUT
          echo "n_head=6" >> $GITHUB_OUTPUT
          echo "n_embd=384" >> $GITHUB_OUTPUT
          echo "max_iters=2000" >> $GITHUB_OUTPUT
          echo "batch_size=4" >> $GITHUB_OUTPUT
          echo "learning_rate=1e-4" >> $GITHUB_OUTPUT
          echo "output_dir=.training-progress/nanecho-cached-scheduled" >> $GITHUB_OUTPUT
          echo "cache_key=scheduled" >> $GITHUB_OUTPUT
        else
          echo "Full training mode - using specified parameters"
          echo "n_layer=8" >> $GITHUB_OUTPUT
          echo "n_head=8" >> $GITHUB_OUTPUT
          echo "n_embd=512" >> $GITHUB_OUTPUT
          echo "max_iters=${{ github.event.inputs.max_iters }}" >> $GITHUB_OUTPUT
          echo "batch_size=8" >> $GITHUB_OUTPUT
          echo "learning_rate=1e-4" >> $GITHUB_OUTPUT
          echo "output_dir=.training-progress/nanecho-cached-full" >> $GITHUB_OUTPUT
          echo "cache_key=full" >> $GITHUB_OUTPUT
        fi
        
        # Cache settings - use safety_check output, not raw input
        echo "force_fresh_start=${{ steps.safety_check.outputs.allow_fresh_start }}" >> $GITHUB_OUTPUT
        echo "max_checkpoints=${{ github.event.inputs.max_checkpoints || '10' }}" >> $GITHUB_OUTPUT
        echo "max_cache_size_gb=${{ github.event.inputs.max_cache_size_gb || '5.0' }}" >> $GITHUB_OUTPUT

    - name: Prepare directory structure
      run: |
        cd echoself
        mkdir -p data/nanecho
        mkdir -p ${{ steps.params.outputs.output_dir }}/cache

    - name: Set PYTHONPATH
      run: |
        echo "PYTHONPATH=${{ github.workspace }}/echoself" >> $GITHUB_ENV

    - name: Cache training artifacts
      uses: actions/cache@v4
      with:
        path: |
          echoself/${{ steps.params.outputs.output_dir }}/cache
          echoself/data/nanecho
        key: nanecho-training-${{ steps.params.outputs.cache_key }}-${{ hashFiles('echoself/nanecho_model.py', 'echoself/training_cache.py') }}
        restore-keys: |
          nanecho-training-${{ steps.params.outputs.cache_key }}-

    - name: Create minimal training data
      run: |
        cd echoself
        
        # Create minimal Echo Self training data for CI
        cat << 'EOFPYTHON' > /tmp/create_training_data.py
        import os
        import numpy as np
        import json
        
        os.makedirs('data/nanecho', exist_ok=True)
        
        # Sample Echo Self text patterns (character-level tokenization for simplicity)
        echo_patterns = [
            'Echo Self is a cognitive architecture with adaptive attention mechanisms.',
            'The persona dimensions include cognitive, introspective, adaptive, and recursive.',
            'Hypergraph patterns enable neural-symbolic reasoning and pattern encoding.',
            'Recursive reasoning allows multi-level introspection and self-examination.',
            'Adaptive attention adjusts thresholds based on cognitive load estimation.',
            'The holographic dimension enables comprehensive system modeling.',
            'Synergistic properties emerge from the interaction of persona dimensions.',
            'Dynamic evolution enables continuous learning and adaptation.',
        ]
        
        # Generate training text
        train_text = ' '.join(echo_patterns * 100)  # Repeat for more data
        val_text = ' '.join(echo_patterns * 20)
        
        # Simple character-level tokenization
        train_tokens = np.array([ord(c) % 256 for c in train_text], dtype=np.uint16)
        val_tokens = np.array([ord(c) % 256 for c in val_text], dtype=np.uint16)
        
        # Ensure minimum size
        min_size = 2048  # Minimum tokens needed
        if len(train_tokens) < min_size:
            train_tokens = np.tile(train_tokens, (min_size // len(train_tokens)) + 1)[:min_size]
        if len(val_tokens) < 512:
            val_tokens = np.tile(val_tokens, (512 // len(val_tokens)) + 1)[:512]
        
        # Save to binary files
        train_tokens.tofile('data/nanecho/train.bin')
        val_tokens.tofile('data/nanecho/val.bin')
        
        # Create metadata
        metadata = {
            'train_tokens': len(train_tokens),
            'val_tokens': len(val_tokens),
            'vocab_size': 256,
            'echo_depth': 7,
            'persona_weight': 0.95,
            'created_by': 'workflow_fallback',
            'description': 'Character-level Echo Self training data for CI'
        }
        
        with open('data/nanecho/metadata.json', 'w') as f:
            json.dump(metadata, f, indent=2)
        
        print(f'‚úÖ Created training data: {len(train_tokens)} train, {len(val_tokens)} val tokens')
        EOFPYTHON
        python /tmp/create_training_data.py

    - name: Run cached training
      run: |
        cd echoself
        
        echo "üöÄ Starting cached training session..."
        echo "üìä Training Parameters:"
        echo "   ‚Ä¢ Layers: ${{ steps.params.outputs.n_layer }}"
        echo "   ‚Ä¢ Embedding: ${{ steps.params.outputs.n_embd }}"
        echo "   ‚Ä¢ Max iterations: ${{ steps.params.outputs.max_iters }}"
        echo "   ‚Ä¢ Force fresh start: ${{ steps.params.outputs.force_fresh_start }}"
        echo "   ‚Ä¢ Max checkpoints: ${{ steps.params.outputs.max_checkpoints }}"
        echo "   ‚Ä¢ Max cache size: ${{ steps.params.outputs.max_cache_size_gb }} GB"
        
        # Create training config
        cat > training_config.json << EOL
        {
          "data_dir": "data/nanecho",
          "out_dir": "${{ steps.params.outputs.output_dir }}",
          "max_iters": ${{ steps.params.outputs.max_iters }},
          "batch_size": ${{ steps.params.outputs.batch_size }},
          "learning_rate": ${{ steps.params.outputs.learning_rate }},
          "device": "cpu",
          "n_layer": ${{ steps.params.outputs.n_layer }},
          "n_head": ${{ steps.params.outputs.n_head }},
          "n_embd": ${{ steps.params.outputs.n_embd }},
          "eval_interval": 100,
          "checkpoint_interval": 200,
          "connection_growth_interval": 100
        }
        EOL
        
        # Run training with caching
        python train_cached.py \
          --config training_config.json \
          --data_dir data/nanecho \
          --out_dir ${{ steps.params.outputs.output_dir }} \
          --max_iters ${{ steps.params.outputs.max_iters }} \
          --batch_size ${{ steps.params.outputs.batch_size }} \
          --learning_rate ${{ steps.params.outputs.learning_rate }} \
          --device cpu \
          --max_checkpoints ${{ steps.params.outputs.max_checkpoints }} \
          --max_cache_size_gb ${{ steps.params.outputs.max_cache_size_gb }} \
          ${{ steps.params.outputs.force_fresh_start == 'true' && '--force_fresh_start' || '' }}

    - name: Analyze training progress
      run: |
        cd echoself
        
        # Show cache statistics
        echo "üìä Final Cache Statistics:"
        cat << 'EOFPYTHON' > /tmp/analyze_progress.py
        from training_cache import TrainingCache, CacheConfig
        import json
        
        cache_config = CacheConfig(cache_dir='${{ steps.params.outputs.output_dir }}/cache')
        cache = TrainingCache(cache_config)
        
        stats = cache.get_cache_stats()
        print(json.dumps(stats, indent=2))
        
        # List checkpoints
        checkpoints = cache.list_checkpoints()
        if checkpoints:
            print('\nüìã Available Checkpoints:')
            for i, ckpt in enumerate(checkpoints[:5]):
                print(f'   {i+1}. {ckpt.checkpoint_id}')
                print(f'      Quality: {ckpt.quality_score:.3f} | Loss: {ckpt.val_loss:.4f}')
                print(f'      Iteration: {ckpt.iteration} | Size: {ckpt.file_size_mb:.1f} MB')
                print(f'      Tags: {chr(44).join(ckpt.tags)}')
        EOFPYTHON
        python /tmp/analyze_progress.py

    - name: Test model generation
      run: |
        cd echoself
        
        # Test if we have a trained model
        if [ -f "${{ steps.params.outputs.output_dir }}/best_model_export.pt" ]; then
          echo "‚úÖ Best model export found"
          ls -la ${{ steps.params.outputs.output_dir }}/best_model_export.pt
          
          # Show model info
          cat << 'EOFPYTHON' > /tmp/test_model.py
        import torch
        
        export_data = torch.load('${{ steps.params.outputs.output_dir }}/best_model_export.pt', map_location='cpu')
        print('üì¶ Exported Model Info:')
        print(f'   Checkpoint ID: {export_data["metadata"]["checkpoint_id"]}')
        print(f'   Quality Score: {export_data["metadata"]["quality_score"]:.3f}')
        print(f'   Validation Loss: {export_data["metadata"]["val_loss"]:.4f}')
        print(f'   Training Iteration: {export_data["metadata"]["iteration"]}')
        print(f'   Connection Ratio: {export_data["metadata"]["metrics"].get("connection_ratio", "N/A")}')
        EOFPYTHON
          python /tmp/test_model.py
        else
          echo "‚ö†Ô∏è No best model export found"
          echo "Available files:"
          ls -la ${{ steps.params.outputs.output_dir }}/
        fi

    - name: Create training summary
      run: |
        cd echoself
        
        # Generate training summary
        cat << 'EOFPYTHON' > /tmp/create_summary.py
        import json
        import os
        from pathlib import Path
        from datetime import datetime
        
        summary = {
            'workflow_run': '${{ github.run_number }}',
            'training_type': '${{ steps.params.outputs.output_dir }}',
            'completed_at': datetime.now().isoformat(),
            'parameters': {
                'max_iters': ${{ steps.params.outputs.max_iters }},
                'batch_size': ${{ steps.params.outputs.batch_size }},
                'learning_rate': ${{ steps.params.outputs.learning_rate }},
                'model_layers': ${{ steps.params.outputs.n_layer }},
                'model_embedding': ${{ steps.params.outputs.n_embd }},
                'force_fresh_start': '${{ steps.params.outputs.force_fresh_start }}' == 'true'
            }
        }
        
        # Add cache statistics if available
        try:
            from training_cache import TrainingCache, CacheConfig
            cache_config = CacheConfig(cache_dir='${{ steps.params.outputs.output_dir }}/cache')
            cache = TrainingCache(cache_config)
            summary['cache_stats'] = cache.get_cache_stats()
            
            # Add best checkpoint info
            best_id = cache.get_best_checkpoint()
            if best_id and best_id in cache.metadata:
                best_metadata = cache.metadata[best_id]
                summary['best_checkpoint'] = {
                    'id': best_id,
                    'quality_score': best_metadata.quality_score,
                    'val_loss': best_metadata.val_loss,
                    'iteration': best_metadata.iteration,
                    'created_at': best_metadata.created_at
                }
        except Exception as e:
            summary['cache_error'] = str(e)
        
        # Save summary
        with open('${{ steps.params.outputs.output_dir }}/training_summary.json', 'w') as f:
            json.dump(summary, f, indent=2)
        
        print('üìù Training Summary:')
        print(json.dumps(summary, indent=2))
        EOFPYTHON
        python /tmp/create_summary.py

    # ================================================================
    # MULTI-LOCATION MODEL BACKUP
    # CRITICAL: Ensure model can NEVER be lost
    # ================================================================

    - name: Backup model to multiple locations
      run: |
        cd echoself
        TIMESTAMP=$(date +%Y%m%d_%H%M%S)

        echo "üõ°Ô∏è MULTI-LOCATION MODEL BACKUP"
        echo "=============================="

        # Create backup directories
        mkdir -p .training-progress/checkpoints
        mkdir -p /tmp/nanecho-checkpoint-backup

        BACKUP_COUNT=0

        # Find the best checkpoint to backup
        BEST_CKPT=""
        if [ -f "${{ steps.params.outputs.output_dir }}/best_model_export.pt" ]; then
          BEST_CKPT="${{ steps.params.outputs.output_dir }}/best_model_export.pt"
        elif [ -f "${{ steps.params.outputs.output_dir }}/cache/checkpoints/latest.pt" ]; then
          BEST_CKPT="${{ steps.params.outputs.output_dir }}/cache/checkpoints/latest.pt"
        fi

        if [ -n "$BEST_CKPT" ] && [ -f "$BEST_CKPT" ]; then
          echo "üì¶ Best checkpoint: $BEST_CKPT"

          # Backup 1: .training-progress/checkpoints (committed to repo)
          cp "$BEST_CKPT" ".training-progress/checkpoints/latest_checkpoint.pt" && {
            cp "$BEST_CKPT" ".training-progress/checkpoints/checkpoint_${TIMESTAMP}.pt"
            echo "‚úì Backed up to .training-progress/checkpoints"
            BACKUP_COUNT=$((BACKUP_COUNT + 1))
          } || echo "‚ö†Ô∏è Failed to backup to .training-progress/checkpoints"

          # Backup 2: /tmp (for additional artifact upload)
          cp "$BEST_CKPT" "/tmp/nanecho-checkpoint-backup/best_model.pt" && {
            echo "‚úì Backed up to /tmp/nanecho-checkpoint-backup"
            BACKUP_COUNT=$((BACKUP_COUNT + 1))
          } || echo "‚ö†Ô∏è Failed to backup to /tmp"

          echo ""
          if [ $BACKUP_COUNT -ge 2 ]; then
            echo "‚úÖ Model backed up to $BACKUP_COUNT locations (SAFE)"
          else
            echo "‚ö†Ô∏è WARNING: Only $BACKUP_COUNT backup(s) succeeded!"
          fi
        else
          echo "‚ö†Ô∏è No best checkpoint found to backup"
          ls -la ${{ steps.params.outputs.output_dir }}/ || true
        fi

    - name: Upload cached training artifacts
      uses: actions/upload-artifact@v4
      with:
        name: nanecho-cached-training-${{ steps.params.outputs.output_dir }}
        path: |
          echoself/${{ steps.params.outputs.output_dir }}/
        retention-days: 30

    - name: Upload checkpoint backup artifact
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: checkpoint-backup-${{ github.run_number }}
        path: |
          echoself/.training-progress/checkpoints/
          /tmp/nanecho-checkpoint-backup/
        retention-days: 90
        if-no-files-found: warn

    - name: Upload training summary
      uses: actions/upload-artifact@v4
      with:
        name: training-summary-${{ steps.params.outputs.output_dir }}
        path: echoself/${{ steps.params.outputs.output_dir }}/training_summary.json
        retention-days: 30
    
    - name: Configure Git
      run: |
        cd echoself
        git config user.name "GitHub Actions Bot"
        git config user.email "actions@github.com"
    
    - name: Commit and push training progress
      run: |
        cd echoself
        
        # Ensure .training-progress directory exists (should already exist from repo)
        mkdir -p .training-progress
        
        # Stage the training progress directory with any new files
        git add .training-progress/
        
        # Check if there are changes to commit
        if git diff --staged --quiet; then
          echo "‚úÖ No new training progress to commit"
        else
          # Commit with detailed message for training session tracking
          git commit -m "chore: update training progress (run ${{ github.run_number }})" \
                     -m "Mode: ${{ steps.params.outputs.cache_key }} | Iters: ${{ steps.params.outputs.max_iters }} | Layers: ${{ steps.params.outputs.n_layer }} | Emb: ${{ steps.params.outputs.n_embd }}" \
                     -m "Workflow: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          
          echo "üì§ Pushing training progress to repository..."
          
          # Generate timestamp once for consistency
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          
          # Determine the target branch: use current branch or fall back to GitHub context
          BRANCH_NAME=$(git symbolic-ref --short HEAD 2>/dev/null || echo "${GITHUB_HEAD_REF:-${GITHUB_REF#refs/heads/}}")
          echo "‚ÑπÔ∏è Pushing to branch: $BRANCH_NAME"
          
          # Multi-layer fallback mechanism to ensure changes are NEVER lost
          PUSH_SUCCESS=false
          
          # Attempt 1: Pull with rebase and push (standard approach)
          echo "üîÑ Attempt 1: Pull with rebase and push..."
          if git pull --rebase origin $BRANCH_NAME 2>&1 && git push origin HEAD:$BRANCH_NAME 2>&1; then
            echo "‚úÖ Push successful on first attempt"
            PUSH_SUCCESS=true
          else
            echo "‚ö†Ô∏è First attempt failed, trying fallback strategies..."
            
            # Attempt 2: Retry with fresh pull and push
            echo "üîÑ Attempt 2: Retry with fresh pull..."
            sleep 2
            if git fetch origin $BRANCH_NAME 2>&1 && \
               git rebase origin/$BRANCH_NAME 2>&1 && \
               git push origin HEAD:$BRANCH_NAME 2>&1; then
              echo "‚úÖ Push successful on second attempt"
              PUSH_SUCCESS=true
            else
              echo "‚ö†Ô∏è Second attempt failed, trying force push with lease..."
              
              # Attempt 3: Force push with lease (safe force push)
              echo "üîÑ Attempt 3: Force push with lease..."
              if git push --force-with-lease origin HEAD:$BRANCH_NAME 2>&1; then
                echo "‚úÖ Force push with lease successful"
                PUSH_SUCCESS=true
              else
                echo "‚ö†Ô∏è Force push with lease failed, trying alternative branch..."
                
                # Attempt 4: Push to alternative timestamped branch as backup
                BACKUP_BRANCH="training-progress-backup-$TIMESTAMP"
                echo "üîÑ Attempt 4: Creating backup branch $BACKUP_BRANCH..."
                if git push origin HEAD:$BACKUP_BRANCH 2>&1; then
                  echo "‚úÖ Changes saved to backup branch: $BACKUP_BRANCH"
                  echo "‚ö†Ô∏è WARNING: Changes are in backup branch $BACKUP_BRANCH, not $BRANCH_NAME"
                  PUSH_SUCCESS=true
                else
                  echo "‚ùå All git push attempts failed!"
                  echo "üÜò CRITICAL: Creating emergency artifact..."
                  
                  # Attempt 5: Save as artifact (last resort - DATA MUST BE PRESERVED)
                  ARTIFACT_DIR="/tmp/training-progress-artifact-$TIMESTAMP"
                  mkdir -p "$ARTIFACT_DIR"
                  
                  # Copy training progress files if they exist
                  if [ -d ".training-progress" ] && [ "$(ls -A .training-progress 2>/dev/null)" ]; then
                    cp -r .training-progress/* "$ARTIFACT_DIR/" 2>/dev/null || true
                  fi
                  
                  {
                    echo "CRITICAL: Git push failed - Training progress saved as artifact"
                    echo "DATA PRESERVATION > SECURITY - Changes must never be lost"
                    echo ""
                    echo "Timestamp: $(date -u +"%Y-%m-%d %H:%M:%S UTC")"
                    echo "Branch: $BRANCH_NAME"
                    echo "Commit: $(git rev-parse HEAD)"
                    echo "Workflow: netrain-cached.yml"
                    echo ""
                    echo "RECOVERY: Download artifact and manually push to repository"
                  } > "$ARTIFACT_DIR/RECOVERY_MANIFEST.txt"
                  
                  echo "üì¶ Emergency artifact created at: $ARTIFACT_DIR"
                  PUSH_SUCCESS=true
                fi
              fi
            fi
          fi
          
          if [ "$PUSH_SUCCESS" = true ]; then
            echo "‚úÖ Training progress successfully saved!"
          else
            echo "‚ùå FATAL: All fallback mechanisms exhausted"
            exit 1
          fi
        fi